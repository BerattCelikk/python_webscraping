<div id="top">

<!-- HEADER STYLE: CLASSIC -->
<div align="center">

# PYTHON_WEBSCRAPING

<em></em>

<!-- BADGES -->
<!-- local repository, no metadata badges. -->

<em>Built with the tools and technologies:</em>

<img src="https://img.shields.io/badge/JSON-000000.svg?style=default&logo=JSON&logoColor=white" alt="JSON">
<img src="https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white" alt="Python">
</div>
<br>

---

## Table of Contents

- [Table of Contents](#table-of-contents)
- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
    - [Project Index](#project-index)
- [Getting Started](#getting-started)
    - [Prerequisites](#prerequisites)
    - [Installation](#installation)
    - [Usage](#usage)
    - [Testing](#testing)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [Acknowledgments](#acknowledgments)

---

## Overview
This project is a Python-based web scraping tool that collects tourist attractions from Wikipedia categories and stores them in a structured JSON file. It demonstrates web scraping, HTML parsing, and JSON data management.



---

## Features
- Scrapes multiple categories of tourist attractions from Wikipedia.
- Extracts name, city, description, and geographic coordinates.
- Stores results in a structured JSON file.
- Handles missing or inconsistent data gracefully.
- Can be extended to include more categories or data points.

---

## Project Structure

```sh
‚îî‚îÄ‚îÄ python_webscraping/
    ‚îú‚îÄ‚îÄ attractions.json      # Scraped data stored in JSON
    ‚îî‚îÄ‚îÄ main.ipynb            # Jupyter Notebook with scraping code
```

### Project Index

<details open>
	<summary><b><code>C:\USERS\BERAT\DESKTOP\PROJELER\PYTHON_WEBSCRAPING/</code></b></summary>
	<!-- __root__ Submodule -->
	<details>
		<summary><b>__root__</b></summary>
		<blockquote>
			<div class='directory-path' style='padding: 8px 0; color: #666;'>
				<code><b>‚¶ø __root__</b></code>
			<table style='width: 100%; border-collapse: collapse;'>
			<thead>
				<tr style='background-color: #f8f9fa;'>
					<th style='width: 30%; text-align: left; padding: 8px;'>File Name</th>
					<th style='text-align: left; padding: 8px;'>Summary</th>
				</tr>
			</thead>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='C:\Users\berat\Desktop\Projeler\python_webscraping/blob/master/attractions.json'>attractions.json</a></b></td>
					<td style='padding: 8px;'>Code>‚ùØ REPLACE-ME</code></td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='C:\Users\berat\Desktop\Projeler\python_webscraping/blob/master/main.ipynb'>main.ipynb</a></b></td>
					<td style='padding: 8px;'>Code>‚ùØ REPLACE-ME</code></td>
				</tr>
			</table>
		</blockquote>
	</details>
</details>

---

## Getting Started

### Prerequisites
- **Python 3.x**
- **Jupyter Notebook**
- **Libraries: `requests`, `beautifulsoup4`, `json`, `time`**

### Installation

Build python_webscraping from the source and intsall dependencies:

1. **Clone the repository:**

    ```sh
    ‚ùØ git clone https://github.com/BerattCelikk/python_webscraping.git
    ```

2. **Navigate to the project directory:**

    ```sh
    ‚ùØ cd python_webscraping
    ```

3. **Install the dependencies:**

    ```sh
    ‚ùØ pip install requests beautifulsoup4
    ```

### Usage

Run the project by opening the `main.ipynb` notebook in Jupyter and executing the cells.  
Alternatively, you can run it as a Python script:

### Testing

There is currently no automated test framework.  
To test the project, run the `main.ipynb` notebook in Jupyter and check that `attractions.json` is populated correctly with valid entries.


---

## Roadmap

- [ ] **Scrape predefined Wikipedia categories** ‚Äì basic scraping working.  
- [ ] **Add more categories or user input** ‚Äì allow users to specify categories to scrape.  
- [ ] **Improve error handling and logging** ‚Äì make scraping more robust.  
- [ ] **Add automated data validation tests** ‚Äì ensure JSON output is correct.

---

## Contributing

- **üí¨ [Join the Discussions](https://LOCAL/Projeler/python_webscraping/discussions)**: Share your insights, provide feedback, or ask questions.
- **üêõ [Report Issues](https://LOCAL/Projeler/python_webscraping/issues)**: Submit bugs found or log feature requests for the `python_webscraping` project.
- **üí° [Submit Pull Requests](https://LOCAL/Projeler/python_webscraping/blob/main/CONTRIBUTING.md)**: Review open PRs, and submit your own PRs.

<details closed>
<summary>Contributing Guidelines</summary>

1. **Fork the Repository**: Start by forking the project repository to your LOCAL account.
2. **Clone Locally**: Clone the forked repository to your local machine using a git client.
   ```sh
   git clone C:\Users\berat\Desktop\Projeler\python_webscraping
   ```
3. **Create a New Branch**: Always work on a new branch, giving it a descriptive name.
   ```sh
   git checkout -b new-feature-x
   ```
4. **Make Your Changes**: Develop and test your changes locally.
5. **Commit Your Changes**: Commit with a clear message describing your updates.
   ```sh
   git commit -m 'Implemented new feature x.'
   ```
6. **Push to LOCAL**: Push the changes to your forked repository.
   ```sh
   git push origin new-feature-x
   ```
7. **Submit a Pull Request**: Create a PR against the original project repository. Clearly describe the changes and their motivations.
8. **Review**: Once your PR is reviewed and approved, it will be merged into the main branch. Congratulations on your contribution!
</details>

<details closed>
<summary>Contributor Graph</summary>
<br>
<p align="left">
   <a href="https://LOCAL{/Projeler/python_webscraping/}graphs/contributors">
      <img src="https://contrib.rocks/image?repo=Projeler/python_webscraping">
   </a>
</p>
</details>

---


## Acknowledgments

- Credit `contributors`, `inspiration`, `references`, etc.

<div align="right">

[![][back-to-top]](#top)

</div>


[back-to-top]: https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square


---
